

\documentclass[times]{elsarticle}

\usepackage{framed}
\usepackage{flushend}
\usepackage[table]{xcolor}
\usepackage[T1]{fontenc}
\usepackage[utf8]{inputenc}
\usepackage{moreverb}

\usepackage[colorlinks,bookmarksopen,bookmarksnumbered,citecolor=red,urlcolor=red]{hyperref}
\pdfminorversion=4

\begin{document}

\title{How the Practice of TDD Influences \\Class Design in Object-Oriented Systems: \\Patterns of Unit Tests Feedback}

\author{Mauricio Finavaro Aniche, Marco Aurélio Gerosa}

\address{
	Department of Computer Sciences\\ 
	Institute of Mathematics and Statistics\\ 
	University of São Paulo (USP)\\ 
	PO Box 66.281 - 05.508-090 - São Paulo - SP - Brazil\\
}

\begin{abstract}

	Despite the fact that Test-Driven Development (TDD) appears to be a software testing practice, 
	many developers affirm that the practice influences on class design. This study aimed
	to better understand the effects of TDD and how the practice influences developers
	during class design on object-oriented systems. 
	We conducted an essentially qualitative exploratory study in which participants
	were invited to implement some exercises using TDD and, based on the data gathered,
	we raised details of how the practice influenced design decisions from the
	participants using interviews.
	We noticed that the practice of TDD drives
	developers during class design by means of constant feedback about its quality. This study
	also named and catalogued feedback patterns perceived by the developers.
	
\end{abstract}

\maketitle

%% ------------------------------------------------------------------------- %%
\section{Introduction}

Test-Driven Development (TDD) is one of the suggested practices
by Extreme Programming (XP) \cite{XPExplained}. The practice is based on
a small cycle, in which a developer writes a test before implementing
the expected functionality and, with the code passing on the
test, the developer refactors it to remove possible code 
and data duplication \cite{TDDByExample}.

The adoption of TDD by the industry has been growing. In a 2010 survey to discover
which practices were used by agile teams, Scott Ambler showed that 53\% of all teams
that replied to the survey adopted TDD as a way to validate the work done
\cite{wambler-survey-agile}. Similar numbers can be found on the annual surveys from
Version One that, in the 2012 version \cite{versionone-2012}, showed that
40\% of the respondent teams have been using the practice.

When using TDD, a developer only writes code that is covered by a test. Due
to that, it is common to relate the practice of TDD to software testing. However,
a common discourse among TDD practitioners is regarding its effects on the internal code quality.
Many authors well-known by industry and academia, such as Kent Beck \cite{TDDByExample}, 
Robert Martin \cite{agile-ppp}, Steve Freeman \cite{GOOS}, and Dave Astels \cite{astels-tdd}, 
state (without scientific evidence) that the practice of TDD promotes a significative
improvement on class design, helping developers to create more cohesive less coupled
classes.

On the other hand, the way in which the practice of TDD guides the developer
through class design is not clear. This was observed in our qualitative study
with TDD practitioners, in a Brazilian agile event. We interviewed
ten participants about TDD effects \cite{aniche-wbma} and, to our surprise,
none of them could satisfactorily explain how the practice guides them to better
designs.
Siniaalto and Abrahamsson \cite{alarming-results} also share this opinion. They also
noticed that the effects of TDD can not be as automatic as expected by most people.
The related work, discussed in Section \ref{cap:trabalhos-relacionados},
only evaluates if the practice of TDD makes any difference in the produced code. Only a few
of them contain a qualitative study that details how the practice makes that difference.
With this information, developers would know how to leverage the practice of TDD in order to 
better create class design.

To understand these reasons, it is necessary to conduct a research on the real world, which
implies on a balance between control and realism. A realistic situation is usually
complex and non deterministic, which makes the comprehension of the phenomenon much
harder. On the other hand, increasing the control of the experiment reduces the
degree of realism, which can take the real factors of influence out of the study
scope \cite{guidelines-case-study}.

Based on the fact that the software development process involves many
human factors and is totally sensitive to the context that it belongs to,
we conducted an essentially qualitative exploratory study in which professionals
from the industry were invited to implement some prepared exercises using TDD and,
based on the gathered data, we investigated the details of how the practice influenced
the participants' class design decisions by means of interviews.

As a result of this study, we raised a few unit tests patterns, which gives developers
feedback on the quality of their class design. These patterns can be used by developers
to improve their class design cheaply.

This paper is divided as follows: in Section \ref{sec:tdd}, we discuss the principles
of Test-Driven Development; in Section \ref{cap:trabalhos-relacionados}, we present
some related work of this research; in Section \ref{sec:planejamento}, we describe the
study design; in Sections \ref{sec:quantitative} and \ref{sec:qualitative}, we present
our quantitative and qualitative results, respectively; in Section \ref{cap:ameacas},
we discuss the threats to validity of this research; in Section \ref{sec:conclusion},
we summarize the findings of this paper.


%% ------------------------------------------------------------------------- %%
\section{Test-Driven Development}
\label{sec:tdd}

Agile software development methods focus on constant feedback \cite{AgileManifesto}. 
Many of the suggested practices
aim to increase the quantity and quality of the feedback; pair programming,
as an example, provides feedback about the code during its writing.

Test-Driven Development, popularized by Kent Beck through his book, \textit{TDD: By Example} (2011)
\cite{TDDByExample}, is one of the practices in which the focus is to give feedback. TDD has
a big importance during the software development cycle because, as suggested by the agile
practices, the class design of a system should emerge as the software grows. And, in order
to quickly respond to this evolution, a constant feedback about internal and external code
quality is required.

TDD is a software development practice that is based on a repetition of a small
cycle. First, developers write a failing test. Then, they make it pass,
by implementing the desired functionality. After that, they refactor the code
to remove code or data duplication that was generated by the process. Moreover,
simplicity is intrinsic to the process: the practitioner writes the simplest
test that fails and writes the simplest implementation that makes the
test pass. This cycle is also known as "Red-Green-Refactor", as it recalls the
colors that a developer usually sees when doing TDD: the red means that a test
is failing, and green means that the test passes successfully.

It is common to relate TDD to software testing practices. Although the creation
of tests is intrinsic to the process, it is also said that TDD helps developers
to create more flexible, cohesive, and less coupled classes \cite{tdd-taxonomy}. 
The tests are the tool used by developers to evaluate the class design that is being developed.
Therefore, many developers refer to TDD 
as \textit{Test-Driven Design} \cite{tdd-taxonomy}.

Authors such as Kent Beck \cite{aim-fire}, Dave Astels \cite{astels-tdd}, and
Robert Martin \cite{bob-martin} state that TDD is, in fact, a class design
technique \cite{tdd-taxonomy} \cite{aim-fire}.
In their opinion, the change in the traditional development cycle, although very simple,
aggregates many other benefits to the produced code: more simplicity, less coupling, and
a high cohesion. Ward Cunningham, one of the Extreme Programming pioneers, summarizes
the discussion in one statement: \textit{"Test-First programming is not a testing technique"} 
\cite{aim-fire}.
According to Janzen, a clearer definition is the one that says that TDD is the 
art of producing automated tests to production code, and using this process to guide
the class design and programming \cite{agilealliance-tdd} \cite{tdd-taxonomy}.

It is a known fact that class design tends to lose quality during the software evolution \cite{evolution-lehman}.
However, it is hard to discuss quality in terms of class design. In this study context,
we used the SOLID principles, detailed in Martin's work \cite{bob-martin}.

It is said that a class design is \textit{rotting} when it becomes hard
to evolve, the code reuse becomes more complicated than replicating the piece
of code, or the cost of doing any changes in the class design becomes high.
Martin \cite{bob-martin} enumerated a few symptoms of a rotten class design,
also known as \textit{class design smells}. They are similar to \textit{code smells},
except that they belong to a higher level: they are present in the general structure
of the software instead of being located in just a single piece of code.

These symptoms can be measured subjectively and, sometimes, objectively. Usually
they are caused by violations of one or more class design principles.
In this study, we make use of the symptoms that were enumerated by him: 
rigidity, fragility, immobility, viscosity, opacity, needless complexity, and
needless repetition. Besides, we also refer to the principles known as SOLID:
Single Responsibility Principle (SRP), Open-Closed Principle (OCP),
Liskov Substitutive Principle (LSP), Interface Segregation Principle (ISP), and
Dependency Inversion Principle (DIP) \cite{bob-martin}.

%% ------------------------------------------------------------------------- %%
\section{Related Work}
\label{cap:trabalhos-relacionados}

Many empirical studies have been conducted to evaluate the effects of TDD.
In most of them, the effects of the practice in the class design are not taken
into account, and only the effect on external quality is measured.
Contrary to what this study proposes, many of them chose
to have a bigger control in the experiment. They were also conduted of the academic
environment, with students that belong to different computer courses.

Janzen \cite{janzen-arch-improvement} showed that the complexity of the algorithms
were much smaller and the code coverage was higher in code written with TDD.
Langr \cite{langr} showed that TDD increases code quality, facilitates
maintenance, and helps to produce 33\% more tests when compared to traditional
approaches.

The study made by George and Williams \cite{george-e-williams} showed that,
although TDD can initially reduce the productivity of the more inexperienced
developers, a qualitative analysis showed that 92\% of the developers think
that TDD helps to maintain the quality of the code, and 79\% believe that
the practice promotes a simpler class design.

A study by Erdogmus \textit{et al.} \cite{erdogmus-morisio} with 24 undergraduate students
showed that TDD increases productivity. However, no difference in code quality
was found.

Another study by Janzen \cite{janzen-saiedian} with three different groups
of students (each one of them using a different approach: TDD, test last, no tests)
showed that the code produced by the TDD team made better use of object-oriented
concepts, and responsibilities were better divided into different classes,
while other teams produced a more procedural code. Also, tested classes were
104\% less coupled than non-tested classes, and methods were 43\%, on average, less complex
than the non-tested ones.

Dogsa and Batic \cite{dogsa-batic} also found an improvement on class design when
using TDD. However, according to the authors, the improvement is a consequence of the simplicity
TDD aggregates to the process. They also affirmed that the test suites created during
the practice favors constant code refactoring.


Li \cite{angela-li} proposed a qualitative study to understand the efficacy of TDD.
In a case study, she collected the perceptions of TDD practitioners about the
benefits of the practices. To achieve that, she interviewed five developers
from software companies in Auckland, New Zealand. The results of the interviews
were analyzed and discussed in terms of code quality, software quality, and
programmer's productivity. Regarding code quality, Li concluded that TDD
guides developers to simpler and better designed classes. In addition, the main
factors that contribute to these benefits are the confidence to refactor and
modify code, a higher code coverage, a deeper understanding of the requirements,
the ease of understanding code, and the elevated
satisfaction of the developers.

TDD practitioners usually make use of other agile practices, such as
pair programming. This makes the evaluation of the practice more difficult.
Madeyski \cite{madeyski-package-dependencies} observed the results
among groups that practiced TDD, groups that practiced pair programming,
and the combination between them, and he was not able to show a significant
difference between teams that use TDD and teams that use pair programming
in terms of class package dependency management. However, when combining
the results, he found that TDD can help managing dependencies at class level.
According to him, developers should use TDD, but they should be aware of 
problems in class design.

Muller and Hagner \cite{muller-e-hagner} showed that TDD does not result in
better quality or productivity. Steinberg \cite{steinberg} showed that
code produced with TDD is more cohesive and less coupled. Students also reported
that defects were easier to fix.

%% ------------------------------------------------------------------------- %%
\subsection{Discussion}

As presented, only a few studies evaluated the effects of TDD on class design.
And, when they did, they only discussed what the effects are and not exactly
\textbf{how} TDD has influenced them. Josefsson \cite{josefsson}, in his discussion
about the need for an architectural phase and the effects of TDD in this matter,
comes to the same conclusion. According to him, studies about TDD that are
found in the current literature are very limited and, because of that, the
"known" effects of the practice in class design can not be explained. Based on
our literature review, we believe that this limitation still exists.

Most of these studies also do not take into account the experience
of the developer who is practicing TDD. Usually they only discuss it
during threats to validity. Janzen \cite{janzen-phd}, in his PhD, perceived
that mature developers obtain more benefits from the practice, writing simpler
classes. Besides, mature developers tend to choose TDD more often than
less experienced developers.

However, studies that analyze TDD from the class design point of view does not
come to conclusive results; many of them even affirm that the effects of TDD
are not so different from those teams that do not practice it. Even the Janzen's PhD
thesis was inconclusive regarding the influence of the practice in coupling
and cohesion \cite{janzen-phd}. 

In addition, another strong point related to class design is simplicity and
the ease to evolve. A rigid class design that does not favor changes is hard
to be evaluated quantitatively. Needless complexity is also subjective.
Therefore, it is necessary more than an analytical comparison; the
developer's point of view should be taken into account.

%% ------------------------------------------------------------------------- %%
\section{Planning and Execution of the Study} 
\label{sec:planejamento}

Conducting an experimental exploratory study in software engineering has always
been a complex task. As suggested by the agile practices \cite{AgileManifesto}, 
one of the reasons is the human factor, very present in 
the software development process. Because of that, the analytic research
paradigm is not enough to investigate complex real cases that involves people
and their interactions with technology \cite{guidelines-case-study}.

A qualitative research is a way to explore and understand the influence that
individuals or groups put on a social or human problem. The research process
involves the emerging of questions and procedures. Data are usually gathered through
the point of view from the participants, with the analysis done in an inductive
way, from a very specific to a general theme. The researcher interprets
the meaning of these data. Data captured by qualitative studies are usually
represented by words and figures. The final report contains a flexible structure.
Researchers that are dedicated to this kind of research support the inductive style and
the importance of showing the complexity of the situation \cite{creswell}.

As discussed in Section \ref{cap:trabalhos-relacionados}, many studies evaluated
TDD, and a few of them even found an improvement on class design, such as
less coupling, high cohesion, and more simplicity. Most of them focused on
the effects of the practice in the produced code, but only a few of them focused on understanding
the possible influence of the practice on the quality of the production code, 
and how TDD really guides developers through these improvements.

To achieve our goal, we chose to conduct an essentially 
exploratory qualitative study with developers in the industry. Participants
were invited to implement a set of pre-prepared exercises. After that,
they were interviewed about how the practice influenced them in their
class design decisions. This section details the planning as well as
the data analysis process.


%% ------------------------------------------------------------------------- %%
\subsection{Research questions}

The main goal of this study was \textbf{to understand the relation between
the practice of TDD and class design decisions taken by programmers in object-oriented
systems}. To achieve it, we answered the following questions:

\begin{enumerate}

	\item \textit{What is the influence of TDD on class design?}

	\item \textit{What is the relationship between TDD and the class design decisions taken
	by a programmer?}

	\item \textit{How does the practice of TDD influence class design in terms of coupling, 
	cohesion, and complexity?}

\end{enumerate}

%% ------------------------------------------------------------------------- %%
\subsection{Research Design}

Participants from different software development companies in the Brazilian
industry were selected. The participants' profiles are discussed in sub-section
\ref{sec:planejamento-participantes}. All of them were invited to implement
a few problems using Java in a defined timeframe. Participants practiced
TDD in one problem and did not practice in the other. The problems,
as well as the instruction of using or not TDD, were
randomized in order to reduce bias.

All implementations were saved to posterior code metrics calculation.
Through them, we obtained relevant information about design quality (cohesion, 
coupling, and simplicity). The chosen metrics were cyclomatic complexity \cite{mccabe},
Fan-Out \cite{lorenz}, lack of cohesion of methods \cite{lcom-hs}, lines per method,
and quantity of methods.

To calculate these metrics, we implemented our own tool. The reason is that
most of the existent tools make use of compiled code (instead of pure source
code). When analyzing many projects at once, it is not an easy task to compile all
of them as each one has its own way of being built.
Our tool contains an automated test suite and is released as open source
\footnote{\url{http://www.metricminer.org.br}. 
Last access on July, the 6th, 2012.}.

In addition, two specialists were invited to analyze the source code and give a score
to each one of them. Although the usefulness of the information passed by the code metrics,
the opinion of a specialist is enriching.

They evaluated the code based on three different categories: \textit{Simplicity}, \textit{Testability},
and \textit{Class Design Quality}. In each category, specialists scored from 1 (bad) to
5 (good) or choose not to evaluate that exercise. As a few participants did not finish the
implementation, specialists were warned to evaluate the intention of the participant and not
only the produced code.
To reduce the bias, the specialists did not know which code was written with TDD.

At the end of the exercise, all participants filled out a survey about their performance
on the exercises. After that, an initial analysis filtered the participants that
were interviewed posteriorly. The selection of the participants was based on
their answers on the survey plus the produced source code. Participants that implemented
a good solution on one problem but not on the other were selected. Besides, participants
that mentioned possible effects of the practice on class design were also interviewed.

The interviews were semi-structured, giving some freedom to the researcher. 
In addition, all questions were open, giving the
opportunity to the participant to talk deeper about the subject.

Since the decisions taken by a programmer during the class design activity can be
influenced by many different factors, the questions were made to make participants
triangulate their answers and to make them isolate the practice of TDD from
the other possible factors of influence. Participants that did not articulate well
the answers were removed from the analysis process.

All interviews were recorded so we were able to transcript and validate all
the captured data. In addition, we took some notes about participants' reactions
to specific questions. The interviews were made in different days,
according to their availability.

%% ------------------------------------------------------------------------- %%
\subsection{Participants' Profile}
\label{sec:planejamento-participantes}

Developers from the Brazilian software development industry were invited to be part
of this research. The participants were evaluated according to their experience in TDD,
software development, Java, and unit tests. The only requirement was that the participant
should already know how to write a unit test.

All participants filled out a survey before the start of the study. In this survey,
besides questioning their experience (quantitatively), it also contained open questions in which
the participant could tell about his experience in object-oriented systems, Java, and
TDD in a more detailed way.

We had 25 participants from 6 different companies. The participants, in their majority,
were not experienced in TDD. 40\% of them affirmed to use TDD for no more than a year.
52\% of them practiced TDD from 1 to 3 years. Only 4\% practiced TDD from 3 to 4
years, and no participant was more experienced than that.

The numbers were a little different when talking about their experience in software
development. 24\% of them worked with software development for the last 4 or 5 years.
28\% of them worked from 6 to 10 years. Only 20\% of them developed software for less
than 2 years. 64\% of the participants use Java. However, 36\% of them do not use
Java in their daily work. All of them know JUnit and 64\% use mock objects 
\footnote{Mock objects are objects created during a unit test. They mock the behavior 
of a concrete object. Usually they are used to isolate the unit test from other classes. 
More information about it can be found on \cite{mocks}.}
during their development activities.
Only 12\% have never heard about mock objects. When talking about object-orientation,
in the open question, most of the participants affirmed to have a good experience
on it. Some of them even affirmed to master the subject. Only a few of them affirmed
to have basic knowledge about OO.

We can also affirm that half of the participants are still trying the practice. The others
are more experienced and have already consolidated the practice. This is positive, as it
was possible to capture information from people with different levels of maturity.

The elevated number of participants that do not use Java in their daily work is consequence
of a company that uses PHP. However, we checked that, although they do not use Java constantly,
they did not have troubles during the implementation of the exercises.

%% ------------------------------------------------------------------------- %%
\subsection{Proposed Problems}
\label{sec:exercicios}

We proposed four problems that should be implemented by the participants
\footnote{The exercises can be found at \url{http://gist.github.com/3024328}. Last access on July, the 30th, 2012.}. 
The goal was to simulate recurrent class design problems in several software projects.
In Table \ref{tab:problemas-exercicios}, we present the relation of a bad implementation of
the exercises and class design principles that were not followed.

It was said to participants that the exercises simulate real world problems and that their code
would be supposedly maintained by another team. Because of that, participants were asked to
implement the most elegant and flexible solution possible.

\begin{table}
	\centering
	\begin{tabular}{| p{3cm} | p{6cm} | p{3cm} | }
		\hline
		\textbf{Exercise} & \textbf{Design Smell} & \textbf{Principles to}\\
		& & \textbf{be Followed}\\
		
		\hline
		
		Exercise 1 & Rigidity, Needless Complexity & SRP, OCP \\
		Exercise 2 & Fragility, Viscosity, Immobility & SRP, DIP, OCP \\
		Exercise 3 & Rigidity, Fragility & SRP\\
		Exercise 4 & Fragility, Viscosity, Immobility & OCP, SRP, DIP \\
		
		\hline
	\end{tabular}
	\caption{Proposed exercises and class design smells}
	\label{tab:problemas-exercicios}
\end{table}

%% ------------------------------------------------------------------------- %%
\section{Quantitative Analysis}
\label{sec:quantitative}

To triangulate the information of the qualitative analysis, we calculated
code metrics to check whether there was a difference in code produced
with the practice of TDD.
We analyzed
264 production classes (831 methods, 2520 lines) and
73 test classes (225 methods, 1832 lines).

The statistical test used was the Wilcoxon. It is a non parametric hypothesis test
used to compare two samples and to check whether there is a difference in the meaning
of both samples. Therefore, we used Wilcoxon to compare the meaning between
the code metrics in code produced with and without TDD. The significance level
used was the standard (0.05).


%% ------------------------------------------------------------------------- %%
\subsection{Code metrics}

In Table \ref{metricas-industria}, we show the \textit{p-values} found for
the differences between codes produced with and without TDD. By the numbers,
we observe that there was no significant differences in cyclomatic complexity
and efferent coupling.
Lack of cohesion of methods was different in two exercises (1 and 4). A difference
also appeared on the quantity of lines in a method (exercise 4) and quantity of
methods (exercise 1).

When looking at the data of all exercises together, no metric presented a significant
difference. We concluded that, at least quantitatively, the practice of TDD did not
make any difference in code metrics.

\begin{table*}
	\centering
	\begin{tabular}{ | p{2cm} | p{2cm} | p{1.7cm} | p{2cm} | p{1.7cm} | p{1.7cm} |}
		\hline
		\textbf{Exercise} & \textbf{Cyclomatic Complexity} & \textbf{Efferent coupling} & \textbf{Lack of Cohesion of Methods} & \textbf{Number of lines per method} 
		& \textbf{Quantity of methods per class} \\
		\hline
		Exercise 1 &	0.8967	&	0.6741 &	\cellcolor[gray]{0.8}2.04E-07* &	0.4962 &	\cellcolor[gray]{0.8}2.99E-06* \\
		Exercise 2	& 0.7868	&	0.7640 &	0.06132 &	0.9925 &	0.7501 \\
		Exercise 3	& 0.5463	&	0.9872 &	0.5471 &	0.7216 &	0.3972\\
		Exercise 4	& 0.2198	&	0.1361 &	\cellcolor[gray]{0.8}0.04891* &	\cellcolor[gray]{0.8}0.0032* &	0.9358\\
		\hline
		All together &	0.8123	&	0.5604 &	0.3278 &	0.06814 &	0.5849\\
		\hline
	\end{tabular}
	\caption{\textit{P-values} found for the difference between code produced with and without TDD}
	\label{metricas-industria}
\end{table*}


In Table \ref{valores-separados}, we calculated the \textit{p-values} of the metric,
splitting them by experience in software development and TDD. The values for the group that
was experienced in TDD and not experienced in software development was not calculated as no
participant fitted on it.

By the numbers, we perceived that cohesion was the only metric that presented a significant
difference for developers that are experienced in software development and TDD.

\begin{table}
	\centering
	\begin{tabular}{ | p{5cm} | p{3.5cm} | p{3.5cm} | }
		\hline
		  & \textbf{Experience in TDD} & \textbf{No experience in TDD} \\
		\hline
			\multicolumn{3}{|c|}{Cyclomatic Complexity} \\
		\hline
			Experience in Software Development 		& 0.09933	&	0.8976\\
			\hline
			No Experience in Software Development 	& NA		&	0.4462\\
		\hline
			\multicolumn{3}{|c|}{Fan-Out}\\
		\hline
			Experience in Software Development 		& 0.1401	&	0.6304\\
			\hline
			No Experience in Software Development 	& NA		&	0.2092\\
		\hline
			\multicolumn{3}{|c|}{Lack of Cohesion of Methods}\\
		\hline
			Experience in Software Development 		& \cellcolor[gray]{0.8}0.03061*	&	0.1284\\
			\hline
			No Experience in Software Development 	& NA		&	0.0888\\
		\hline
			\multicolumn{3}{|c|}{Quantity of Methods per Class} \\
		\hline
			Experience in Software Development 		& 0.09933	&	0.8976\\
			\hline
			No Experience in Software Development 	& NA		&	0.4462\\
		\hline
			\multicolumn{3}{|c|}{Lines per Method}\\
		\hline
			Experience in Software Development 		& 0.0513	&	0.4319\\
			\hline
			No Experience in Software Development 	& NA		&	0.5776\\
		\hline
	\end{tabular}
	\caption{\textit{P-values} found for the difference in metrics between experienced and non experienced participants}
	\label{valores-separados}
\end{table}

%% ------------------------------------------------------------------------- %%
\subsection{Specialists}

In Table
\ref{tab:especialistas-industria}, we presented the \textit{p-values} found for the
difference in the specialists' evaluation of code produced with and without TDD.
By the numbers, we observed that both specialists did not find any difference.

\begin{table}[h!]
	\centering
	\begin{tabular}{| p{2cm} | c | c | c | }
		\hline
		\textbf{Specialist} & \textbf{Class Design} & \textbf{Testability} & \textbf{Simplicity}\\
		\hline
		Specialist 1 &	0.4263 &	0.5235 &	0.3320\\
		Specialist 2 &	0.7447 &	0.4591 &	0.9044\\
		\hline
	\end{tabular}
	\caption{\textit{P-values} found for the difference in specialists' analysis}
	\label{tab:especialistas-industria}
\end{table}

%% ------------------------------------------------------------------------- %%
\section{Qualitative Analysis}
\label{sec:qualitative}

The values presented above corroborate with many of the related work.
Apparently TDD does not influence the code to the point of changing
the metric values for coupling, cohesion, and simplicity. However, this is
incoherent to the industry's common feeling of the positive effects of TDD on class design.
As stated, in this study we conducted a qualitative analysis to understand
how this influence goes from the point of view of the developers.

In this section we present and discuss about the analysis and interpretation of
the qualitative data gathered during the execution of this study. In particular,
in Section \ref{padroes-tdd}, we define some patterns about the feedback the practice
of TDD gives to the developer.

An interesting point is that the participants, regardless of their experience on TDD or
software development, commented on similar points. Because of that, we did not separate
discussions in the categories presented in Section \ref{sec:planejamento}.

%% ------------------------------------------------------------------------- %%
\subsection{Interview analysis}

Different from what was expected, the majority of the participants affirmed that the
practice of TDD would not change the class design produced by them during the exercises
in which they did not use the practice.
The main justification was that experience and previous knowledge on object-orientation
guided them during the class design. All participants agreed that a developer with no
knowledge in any of the mentioned areas would create a good class design only by practicing
TDD.

Two good examples that reinforce the point were given by the participants. One of them
said that he made use of a design pattern \cite{gof} that he had learned a few days before. Another
participant mentioned that his studies on SOLID principles helped him during the exercises.
The transcription below was extracted from the interviews:

\begin{framed}
	\textit{"It was even funny. I am reading the Design Patterns (book), and it discusses about polymorphism. 
	My implementation was based on that, because I've never done something like that before (...), here I rarely
	create new stuff, I just maintain legacy code."}
\end{framed}

In addition, the only participant from the industry that had never practiced TDD before
affirmed that he did not feel any improvement in the class design when practicing.
Curiously, this participant said that he already knew that "TDD was a design technique".
It somehow indicates that the popularity of the effects of TDD in class design
is big.
That opinion was slightly different from the experienced participants, 
who affirmed that TDD was not only about design, but also about testing.

However, contrary to the fact that TDD does not guide developers directly to a
good class design, all participants believe that TDD has positive effects on class design.
Many of them even mentioned the difficulty when trying to stop using TDD:

\begin{framed}

	\textit{"When you are about to implement something, you end up thinking on the tests that you will do. 
	It is hard to think like "write code without thinking on tests!". As soon as you get used to it, 
	you just don't know another way to write code..."}
	
\end{framed}

According to them, TDD can help during class design process but, to achieve that,
the developer should have certain experience in software development. Most participants
affirmed that their class designs were based on their experiences and past learning process.
In their opinion, the best option is to join the practice of TDD and experience:

\begin{framed}

	\textit{"The ideal is to put both things together [experience and TDD] (...) 
	I don't believe that TDD by itself could make things get better. There are many other
	concepts [that a developer should know] to make things good."}

\end{framed}

%% ------------------------------------------------------------------------- %%
\subsection{Rapid Feedback}

The majority of the participants also commented that one difference that is
perceived when they practice TDD is the constant feedback. In traditional testing,
the time between the production code writing and test code writing is too long.
When practicing TDD, developers are forced to write the test first, and receive all
feedback a test can provide sooner.

\begin{framed}
	\textit{"You would look to test and say: "Is it ok? Is it not?", and would do it again."}
\end{framed}

A participant commented that, with the test, developers can observe
and criticize the code they are writing. As it is done constantly,
developers end up continuously thinking about the code and its
quality:

\begin{framed}
	\textit{"When you write the test, you soon perceive what you don't like about it (...), 
	you don't perceive that until you start using tests."}
\end{framed}

Reducing the time between the code writing and test writing also helps developers to
create a code that effectively solves the problem. According to the participants, in traditional
testing, developers write too much code before actually knowing if it works:

\begin{framed}
	\textit{"[The test] is not only a specification; it should actually work. So, as you really reduce
	the time between writing a software that works and to test it, you end up by perceiving if that
	part works or not quicker (...)"}
\end{framed}

%% ------------------------------------------------------------------------- %%
\subsection{The Search for Testability}

Maybe the main reason the practice of TDD helps developers in their class design is
by the constant search for testability. It is possible to infer that,
when starting to produce code by its test, the production code should be, necessarily,
possible to be tested.

On the other hand, when code is not easy to be tested, developers understand that
as a class design smell. When it happens, developers usually try to refactor
the code to make it easier to be tested. One participant also affirmed that he
takes it as a rule: if it is hard to test, then the code can be improved.

\begin{framed}
	\textit{"I take it as a rule: every time it is very complex [the test],
	I think we should stop and refactor because, in my opinion, it can be simpler."}	
\end{framed}

That point had already been raised by Feathers \cite{feathers-synergy}.
The harder it is to write the test, the bigger the chance of a class design problem.
According to him, there is a big synergy between a high testable class and
a good class design: if developers are looking for testability, they end up by
creating a good class design; if they are looking for a good class design, they end
up by writing testable code.

In that search for testability, developers are encouraged to write code
that is easily testable. Codes like that contain a few interesting
characteristics, such as the ease of invoking the expected behavior,
the non need of complicated pre-conditions, and the explicit declaration
of all dependencies.

The participants went even further. During the interviews, many of them
mentioned about many patterns they have found in unit tests. These patterns
make them think about possible design problems in the class they are building.
These patterns are discussed in the following sub-sections.

%% ------------------------------------------------------------------------- %%
\subsection{TDD Feedback Patterns}
\label{padroes-tdd}

As mentioned before, most of the feedback a test gives occurs at the moment
when the developer finds a difficulty when writing the test. This sub-section discusses
patterns mentioned by the participants that make them believe that there is a
problem in the class design.

%% ------------------------------------------------------------------------- %%
\subsubsection{Patterns Related to Cohesion}

When only one method requires too many unit tests to assure its behavior,
it is probably too complex and/or contains many different responsibilities.
Codes like that usually contain many different paths and tend to update
many internal attributes of the object. In those cases, developers
are required to write many tests to cover all possible scenarios.
We call this pattern \textbf{Many Tests to a Method}.

The same idea can be generalized to the class. Classes that expose too 
many methods to the external world also tend to have many responsibilities.
Classes like that may be refactored as well.
We call this pattern \textbf{Many Tests to a Class}.

Another cohesion smell can be found when a developer feels the need
of writing big scenarios for only one class or method. It is possible to infer
that this need emerges in classes that deal with too many objects or
contain too many responsibilities. We call it \textbf{Too Big Scenario}.

One pattern that was not explicitly mentioned by the participants, but
noticed by us, is when a developer feels the need to test a method
that is not public. Private methods usually help to transform a public method
into something easier to be read. When trying to test it in an isolated
way, the developer may have found a method that contains too much responsibility.
That responsibility can be moved to a different class. We call it \textbf{Tests in Non Public Methods}.

%% ------------------------------------------------------------------------- %%
\subsubsection{Patterns Related to Coupling}

The abusive use of mock objects to test a single class indicates that
the class under test has coupling issues. It is possible to infer that a class
that makes use of many mock objects depends upon many classes and, therefore,
tends to be an unstable class. We call it \textbf{Too Many Mock Objects}.

Another pattern perceived by us is the creation of mock objects that are
not used in some test methods. That usually happens when the class
is highly coupled, and the result of one dependency does not infer in
the other. When it happens, the programmer ends up writing a set of tests,
in which some of them deal with a subset of mock objects, while other
tests deal with the other subset of mock objects. It indicates that
the class is highly coupled and needs to be refactored. We call it
\textbf{Non Used Mock Objects}.

%% ------------------------------------------------------------------------- %%
\subsubsection{Patterns Related to Abstractions}

The lack of an abstraction usually makes that a simple change needs to
be done in different pieces of code. When requirements change and
developers are obligated to do the same change in different tests,
that indicates a lack of a correct abstraction to represent the problem
and avoid the code repetition. We call it \textbf{Same Change in Different Tests}.
Analogously, developers can perceive the same thing when they create the
same tests for different entities. We call it \textbf{Repeated Tests for Different Entities}.

When a developer starts the test and notices that the public interface of the class
is not easy to be consumed, it may indicate that the current abstraction is not
clear enough and can be improved. We call it \textbf{Non Friendly Interface}.

Also, the existence of the word \textit{"if"} in the name of the test is another
pattern. Tests that contain a name like that usually indicate the existence
of an "if" in the production code. Those many conditions might be refactored and,
through the use of polymorphism, eliminated. We call it \textbf{Conditional in Test's name}.

%% ------------------------------------------------------------------------- %%
\subsection{Relation between Patterns and Class Design Principles}

It is possible to relate feedback patterns raises by the participants to the class design
smells mentioned in this study.
In Table \ref{tab:relacao-padroes}, we present the relationship and how the patterns
can help developers to search for class design problems.

\begin{table}[h!]
	\centering
	\begin{tabular}{| p{4.5cm} | p{4.5cm} | p{3cm} | }
		\hline

		\textbf{Pattern} & \textbf{Class Design Smell} & \textbf{Not Followed Principles}\\
		
		\hline

		Many Tests to a Method                   & Needless Complexity, Opacity   & SRP \\ \hline
		Many Tests to a Class                  & Needless Complexity, Opacity   & SRP \\ \hline
		Too Big Scenario                           & Opacity, Fragility                  & SRP \\ \hline
		Tests in non Public Method             & Needless Complexity              & SRP, OCP \\ \hline
		Too Many Mock Objects                       & Fragility                             & DIP, OCP \\ \hline
		Non Used Mock Objects                  & Fragility                             & DIP, OCP \\ \hline
		Same Change in Different Tests           & Fragility, Rigidity                    & SRP \\ \hline
		Repeated Tests for Different Entities     & Needless Repetition, Rigidity        & SRP  \\ \hline
		Non Friendly Interface                         & Opacity                               & ISP \\ \hline
		Conditional in Test's name                   & Rigidity, Fragility                    & SRP, OCP \\

		\hline
		
	\end{tabular}
	\caption{Relationship between TDD feedback patterns and class design smells}
	\label{tab:relacao-padroes}
\end{table}

%% ------------------------------------------------------------------------- %%
\section{Threats to Validity}
\label{cap:ameacas}

%% ------------------------------------------------------------------------- %%
\subsection{Construction Validity}

%% ------------------------------------------------------------------------- %%
\subsubsection{Small Exercises}

The proposed exercises were small compared to a real project. However, all exercises
contain localized class design problems. Once this study evaluates the effects
of TDD on class design, we believe the exercises can simulate real design problems
satisfactorily.
Besides, at the end of the implementation, participants answered a question about the
similarity between the exercises and real world problems. All of them affirmed that
the problems found in the exercises were very similar to the ones they deal with in real world.

%% ------------------------------------------------------------------------- %%
\subsection{Internal validity}

%% ------------------------------------------------------------------------- %%
\subsubsection{Recent effects of TDD in Participants' Mind}

Many participants use TDD in their daily work. This can bias participants so they
won't be able to analyze the advantages and disadvantages of the practice.
To reduce the bias, participants implemented one exercise without TDD, so both
development practices are fresh in their minds.

%% ------------------------------------------------------------------------- %%
\subsubsection{Non Finished Exercises}

Some participants did not finish their implementation. This can influence the
quantitative analysis, as a design that would be complex at the end, looks simple
to an automated code metric.

%% ------------------------------------------------------------------------- %%
\subsubsection{Researcher's influence}

Researchers are a fundamental key in qualitative research. They can influence
the interpretation of the results because of past experiences.
In this study, our opinion had a strong influence on the participants selection
to the interview.
Besides, the exercises were created by us and, somehow, this may have influenced
the TDD practiced. To reduce this problem, we reviewed all analysis, looking for
non clear or incorrect conclusions.


%% ------------------------------------------------------------------------- %%
\subsection{External Validity}

%% ------------------------------------------------------------------------- %%
\subsubsection{Desirability bias}

Desirability bias is the scientific term used to describe the tendency of some participants
to reply questions in a way that they will be accepted by the other members
of community \cite{crowne}.
Agile methods and TDD have a strong speech. The Brazilian agile community is still
young and it is possible to empirically perceive that many developers just
repeat the discourse without a great experience or knowledge of the subject.

In this study context, a possible bias would be a participant that replies
what the literature says, and not exactly what s/he feels about the practice.
To reduce the bias, we would eliminate participants that replied questions superficial.
In practice that did not happen. Only a few answers were superficially (and these
ones were eliminated).

%% ------------------------------------------------------------------------- %%
\subsubsection{Quantity of participants}

Although we contacted many different companies and software development groups,
the number of participants invited may not have been enough to generalize the findings.

%% ------------------------------------------------------------------------- %%
\section{Conclusion}
\label{sec:conclusion}
%\section{Conclusão}


In this study, we discussed and understood how the TDD practice can make the
difference in classes design.
In addition, besides endorsing the quantitative studies from the literature, this study
goes beyond and analyzes feedback patterns that appeared in the moment when
the developer uses TDD and, in practice, guides him during the design.

It is expected, with this cataloged patterns, that developers pay more attention
to the potential feedbacks that TDD brings and, use them to improve their class
design. The teaching of TDD can also be assisted by this study, considering
that teachers can use the patterns raised here and show to students
how the practice can, actually guide the developer to a better class design.


A possible future work is the developing of tools that automatically detect these patterns
and warn the developer about a possible code smell in design. Besides that,
the search for more patterns like the ones shown here can improve even more the feedback
provided by the practice.

In below subsections, we answer each of the questions raised by this study.

\subsection{What is the influence of TDD in class design?}

The practice of TDD \textbf{can} affect the creating process of class design. However,
unlike the comments made by the industry, \textbf{the TDD practice cannot guide the
developer to a good class design automatically}; the experience and knowledge of
the developer are essential to develop oriented object software.

The practice, through the possible feedbacks on class design, heavily
discussed in Section \ref{padroes-tdd}, can be a guide to the developer.
These feedbacks, when noted, make the developer realize problems in class
design beforehand, facilitating code refactoring (Q1 and Q2).

\textbf{Therefore, this is the way how the practice guides the developer to
a better class design; giving constant feedback about potential issues in
class design. It is a developer's task to realize these issues and, 
improve the design. }

\subsection{What is the relation between TDD and design decisions made by
a developer?}

The developer that uses TDD writes tests before the code. This makes
the current unit test to be treated as a draft by the developer.
\textbf{Noticing carefully the code of the unit test, the developer can
realize issues in class design that s/he is writing. As an example,
classes with too many responsibilities or with too many dependencies}.

\subsection{How the TDD practice affects the programmer in the process of designing
classes, about the coupling, cohesion and complexity?}

When writing a unit test to a specific class, the developer is forced to follow
the same steps: writing of the scenario, execution of the action being
tested, and assuring that the behavior was executed as
expected.
\textbf{Any trouble writing these steps can imply issues in the class design}. 
The attentive developer notices and improves the respective design class.

%% ------------------------------------------------------------------------- %%
\section*{Acknowledgement}

We thank the companies that participated in this study: Caelum, Bluesoft,
Amil e WebGoal (São Paulo and Poços de Caldas). Besides, we thank the
developers that took part in this research independently.

%% ------------------------------------------------------------------------- %%
\begin{thebibliography}{9}


	\bibitem{XPExplained}
	K.~Beck, \emph{Extreme Programming Explained}, 2nd~ed.\hskip 1em plus 0.5em
	  minus 0.4em\relax Addison-Wesley Professional, 2004.

	\bibitem{TDDByExample}
	------, \emph{Test-Driven Development By Example}, 1st~ed.\hskip 1em plus 0.5em
	  minus 0.4em\relax Addison-Wesley Professional, 2002.

	\bibitem{wambler-survey-agile}
	S.~Wambler, ``How agile are you? 2010 survey results,''
	  \url{http://www.ambysoft.com/surveys/howAgileAreYou2010.html}, 2010, Último
	  acesso em 28/10/2010.

	\bibitem{versionone-2012}
	V.~One, ``State of agile development survey results,''
	  \url{http://www.versionone.com/state_of_agile_development_survey/11/}, 2012,
	  Último acesso em 29/02/2012.

	\bibitem{agile-ppp}
	R.~Martin, \emph{Agile Principles, Patterns, and Practices in C\#},
	  1st~ed.\hskip 1em plus 0.5em minus 0.4em\relax Prentice Hall, 2006.

	\bibitem{GOOS}
	S.~F. e~Nat~Pryce, \emph{Growing Object-Oriented Software, Guided by Tests},
	  1st~ed.\hskip 1em plus 0.5em minus 0.4em\relax Addison-Wesley Professional,
	  2009.

	\bibitem{astels-tdd}
	D.~Astels, \emph{Test-Driven Development: A Practical Guide}, 2nd~ed.\hskip 1em
	  plus 0.5em minus 0.4em\relax Prentice Hall, 2003.

	\bibitem{aniche-wbma}
	M.~Aniche, T.~Ferreira, and M.~Gerosa, ``What concerns beginner test-driven
	  development practitioners: A qualitative analysis of opinions in an agile
	  conference,'' 2011.

	\bibitem{alarming-results}
	M.~Siniaalto and P.~Abrahamsson, ``Does test-driven development improve the
	  program code? {Alarming} results from a comparative case study,''
	  \emph{Balancing Agility and Formalism in Software Engineering}, vol. 5082,
	  pp. 143--156, 2008. [Online]. Available:
	  \url{http://dx.doi.org/10.1007/978-3-540-85279-7_12}

	\bibitem{guidelines-case-study}
	P.~Runeson and M.~Host, ``Guidelines for conducting and reporting case study
	  research in software engineering,'' \emph{Empirical Software Engineering},
	  vol.~14, no.~2, pp. 131--164, 2009.

	\bibitem{AgileManifesto}
	K.~Beck, M.~Beedle, A.~van Bennekum, A.~Cockburn, W.~Cunningham, M.~Fowler,
	  J.~Grenning, J.~Highsmith, A.~Hunt, R.~Jeffries, J.~Kern, B.~Marick, R.~C.
	  Martin, S.~Mellor, K.~Schwaber, and J.~S.~D. Thomas, ``Manifesto for agile
	  software development,'' \url{http://agilemanifesto.org/}, 02 2001, Último
	  acesso em 01/10/2010.

	\bibitem{tdd-taxonomy}
	D.~Janzen and H.~Saiedian, ``Test-driven development concepts, taxonomy, and
	  future direction,'' \emph{Computer}, vol.~38, no.~9, pp. 43 -- 50, sept.
	  2005.

	\bibitem{aim-fire}
	K.~Beck, ``Aim, fire,'' \emph{IEEE Software}, vol.~18, pp. 87--89, 2001.

	\bibitem{bob-martin}
	R.~C. Martin, \emph{Agile Software Development, Principles, Patterns, and
	  Practices}, 1st~ed.\hskip 1em plus 0.5em minus 0.4em\relax Prentice Hall,
	  2002.

	\bibitem{agilealliance-tdd}
	A.~Alliance, ``Test-driven development,''
	  \url{http://www.agilealliance.org/programs/roadmaps/Roadmap/tdd/tdd_index.htm},
	  2005.

	\bibitem{janzen-arch-improvement}
	D.~S. Janzen, ``Software architecture improvement through test-driven
	  development,'' in \emph{Companion to the 20th annual ACM SIGPLAN conference
	  on Object-oriented programming, systems, languages, and applications}, ser.
	  OOPSLA '05.\hskip 1em plus 0.5em minus 0.4em\relax New York, NY, USA: ACM,
	  2005, pp. 240--241. [Online]. Available:
	  \url{http://doi.acm.org/10.1145/1094855.1094954}

	\bibitem{langr}
	J.~Langr, ``Evolution of test and code via test-first design,''
	  \url{http://www.objectmentor.com}, 2001, Último acesso em 01/03/2011.

	\bibitem{george-e-williams}
	B.~George and L.~Williams, ``An initial investigation of test driven
	  development in industry,'' in \emph{Proceedings of the 2003 ACM symposium on
	  Applied computing}.\hskip 1em plus 0.5em minus 0.4em\relax ACM, 2003, pp.
	  1135--1139.

	\bibitem{erdogmus-morisio}
	H.~Erdogmus, M.~Morisio, and M.~Torchiano, ``On the effectiveness of the
	  test-first approach to programming,'' \emph{IEEE Transactions on Software
	  Engineering}, vol.~31, pp. 226--237, 2005.

	\bibitem{janzen-saiedian}
	D.~Janzen and H.~Saiedian, ``On the influence of test-driven development on
	  software design,'' \emph{Proceedings of the 19th Conference on Software
	  Engineering Education and Training (CSEET'06)}, pp. 141--148, 2006.

	\bibitem{dogsa-batic}
	T.~Dogsa and D.~Batic, ``The effectiveness of test-driven development: an
	  industrial case study,'' \emph{Software Quality Journal}, pp. 1--19, 2011,
	  10.1007/s11219-011-9130-2. [Online]. Available:
	  \url{http://dx.doi.org/10.1007/s11219-011-9130-2}

	\bibitem{angela-li}
	A.~L. Li, ``Understanding the efficacy of test driven development,'' Master's
	  thesis, Auckland University of Technology, 2009.

	\bibitem{madeyski-package-dependencies}
	L.~Madeyski, ``The impact of pair programming and test-driven development on
	  package dependencies in object-oriented design - an experiment,'' in
	  \emph{Product-Focused Software Process Improvement}, ser. Lecture Notes in
	  Computer Science, J.~Munch and M.~Vierimaa, Eds.\hskip 1em plus 0.5em minus
	  0.4em\relax Springer Berlin / Heidelberg, 2006, vol. 4034, pp. 278--289.
	  [Online]. Available: \url{http://dx.doi.org/10.1007/11767718_24}

	\bibitem{muller-e-hagner}
	M.~Muller and O.~Hagner, ``Experiment about test-first programming,''
	  \emph{Software, IEEE Proceedings -}, vol. 149, no.~5, pp. 131 -- 136, oct
	  2002.

	\bibitem{steinberg}
	D.~H. Steinberg, ``The effect of unit tests on entry points, coupling and
	  cohesion in an introductory java programming course,'' \emph{XP Universe},
	  2001.

	\bibitem{josefsson}
	M.~Josefsson, ``Making architectural design phase obsolete - tdd as a design
	  method,''
	  \url{http://www.soberit.hut.fi/T-76.5650/Spring_2004/Papers/M.Josefsson_76650_final.pdf},
	  2004, t-76.650 Seminar course on SQA in Agile Software Development Helsinki
	  University of Technology. Último acesso em 01/03/2011.

	\bibitem{janzen-phd}
	D.~Janzen, ``An empirical evaluation of the impact of test-driven development
	  on software quality,'' Ph.D. dissertation, University of Kansas, 2006.

	\bibitem{creswell}
	J.~W. Creswell, \emph{Research design: qualitative, quantitative, and mixed
	  methods approaches}, 3rd~ed.\hskip 1em plus 0.5em minus 0.4em\relax Sage
	  Publications, 2008.

	\bibitem{mccabe}
	T.~McCabe, ``A complexity measure,'' \emph{IEEE TSE}, vol.~4, pp. 308--320,
	  1976.

	\bibitem{lorenz}
	J.~Lorenz, M.;~Kidd, \emph{Object-Oriented Software Metrics: A Practical
	  Guide}.\hskip 1em plus 0.5em minus 0.4em\relax Prentice-Hall, 1994.

	\bibitem{lcom-hs}
	B.~Henderson-Sellers, \emph{Object-oriented metrics: measures of
	  complexity}.\hskip 1em plus 0.5em minus 0.4em\relax Prentice-Hall, 1996.

	\bibitem{evolution-lehman} Lehman, M. Laws of software evolution revisited.
	Lecture Notes in Computer Science, Software Process Technology, 1996.
	
	\bibitem{mocks}
	C.~P. Mackinnon~T., Freeman~S., ``Endotesting: unit testing with mock
	  objects,'' in \emph{Extreme Programming Examined}, G.~Succi and M.~Marchesi,
	  Eds.\hskip 1em plus 0.5em minus 0.4em\relax Addison-Wesley Longman Publishing
	  Co., 2001, pp. 287--301.

	\bibitem{gof}
	e.~a. Eric T~Freeman, Elisabeth~Robson, \emph{Head First Design Patterns},
	  1st~ed.\hskip 1em plus 0.5em minus 0.4em\relax O'Reilly Media, 2004.

	\bibitem{feathers-synergy}
	M.~Feathers, ``The deep synergy between testability and good design,''
	  \url{http://michaelfeathers.typepad.com/michael_feathers_blog/2007/09/the-deep-synerg.html},
	  2007, Último acesso em 27/10/2010.

	\bibitem{crowne}
	D.~P. Crowne and D.~Marlowe, ``A new scale of social desirability independent
	  of psychopathology,'' \emph{Journal of Consulting Psychology}, vol.~24, pp.
	  349--354, 1960.


\end{thebibliography}

\end{document}
